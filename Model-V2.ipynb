{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import os\n",
    "import logging\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logging setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"FIFTYONE_DEFAULT_DATASET_DIR\"] = \"Z:/open_images_v7\"\n",
    "fo.config.dataset_zoo_dir = \"Z:/open_images_v7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = augment_image(image)\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset, batch_size=32, shuffle_buffer=1000):\n",
    "    dataset = dataset.shuffle(shuffle_buffer)\n",
    "    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Food101**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from C:\\Users\\Troxi\\tensorflow_datasets\\food101\\2.0.0\n",
      "INFO:absl:Reusing dataset food101 (C:\\Users\\Troxi\\tensorflow_datasets\\food101\\2.0.0)\n",
      "INFO:absl:Creating a tf.data.Dataset reading 32 files located in folders: C:\\Users\\Troxi\\tensorflow_datasets\\food101\\2.0.0.\n",
      "INFO:absl:Creating a tf.data.Dataset reading 16 files located in folders: C:\\Users\\Troxi\\tensorflow_datasets\\food101\\2.0.0.\n",
      "INFO:absl:Constructing tf.data.Dataset food101 for split ['train', 'validation'], from C:\\Users\\Troxi\\tensorflow_datasets\\food101\\2.0.0\n"
     ]
    }
   ],
   "source": [
    "food101_dataset = tfds.load('food101', split=['train', 'validation'], as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Open Images V7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_classes = [\"Egg (Food)\", \"Fast food\", \"Food\", \"Seafood\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_v7_dataset = foz.load_zoo_dataset(\n",
    "    \"open-images-v7\",\n",
    "    splits=[\"train\", \"validation\"],\n",
    "    classes=food_classes,\n",
    "    max_samples=10000  # Adjust this number as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_food101, y_food101 = load_and_preprocess_data(food101_dataset['train'])\n",
    "x_open_v7, y_open_v7 = load_and_preprocess_data(open_v7_dataset['train'])\n",
    "\n",
    "x_train = np.concatenate([x_food101, x_open_v7])\n",
    "y_train = np.concatenate([y_food101, y_open_v7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tf.data.Dataset\n",
    "train_dataset = prepare_dataset(tf.data.Dataset.from_tensor_slices((x_train, y_train)))\n",
    "val_dataset = prepare_dataset(tf.data.Dataset.from_tensor_slices((x_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    checkpoint,\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset, callbacks=callbacks)\n",
    "\n",
    "base_model.trainable = True\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_dataset, epochs=20, validation_data=val_dataset, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_food(image_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "    \n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    \n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nutrition data integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition_data = pd.read_csv(\"Nutrition-Data/nutrients_csvfile.csv\")\n",
    "\n",
    "def get_nutrition_info(food_item):\n",
    "    try:\n",
    "        nutrition = nutrition_data[nutrition_data['food_item'] == food_item].iloc[0]\n",
    "        return {\n",
    "            'calories': nutrition['calories'],\n",
    "            'protein': nutrition['protein'],\n",
    "            'carbs': nutrition['carbs'],\n",
    "            'fat': nutrition['fat']\n",
    "        }\n",
    "    except IndexError:\n",
    "        return get_nutrition_info_from_api(food_item)\n",
    "\n",
    "# API CALL WHEN NUTRITION VALUERS ARE NOT IN THE LOCAL DATASET\n",
    "API_KEY = \"hydUyBjWVdUlt1qNIeB2dKGgQYbjFiQwMjm6YpBn\" \n",
    "API_ENDPOINT = \"https://api.nal.usda.gov/fdc/v1/foods/search\"\n",
    "\n",
    "def get_nutrition_info_from_api(food_item):\n",
    "    params = {\n",
    "        \"api_key\": API_KEY,\n",
    "        \"query\": food_item,\n",
    "        \"dataType\": [\"Survey (FNDDS)\"],\n",
    "        \"pageSize\": 1\n",
    "    }\n",
    "    \n",
    "    response = requests.get(API_ENDPOINT, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data['foods']:\n",
    "            food = data['foods'][0]\n",
    "            nutrients = food['foodNutrients']\n",
    "            \n",
    "            nutrition_info = {\n",
    "                'calories': next((n['value'] for n in nutrients if n['nutrientName'] == 'Energy'), None),\n",
    "                'protein': next((n['value'] for n in nutrients if n['nutrientName'] == 'Protein'), None),\n",
    "                'carbs': next((n['value'] for n in nutrients if n['nutrientName'] == 'Carbohydrate, by difference'), None),\n",
    "                'fat': next((n['value'] for n in nutrients if n['nutrientName'] == 'Total lipid (fat)'), None)\n",
    "            }\n",
    "            \n",
    "            return nutrition_info\n",
    "    \n",
    "    # If API call fails or no data found, return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def food_recognition_and_nutrition(image_path):\n",
    "    try:\n",
    "        predicted_class = predict_food(image_path)\n",
    "        food_item = class_labels[predicted_class]  # You need to define class_labels\n",
    "        nutrition_info = get_nutrition_info(food_item)\n",
    "        \n",
    "        return {\n",
    "            'food_item': food_item,\n",
    "            'nutrition_info': nutrition_info\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in food recognition: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFLITE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFLite conversion\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('food_recognition_model_v2.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"TensorFlow Lite model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
