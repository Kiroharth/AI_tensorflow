{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import os\n",
    "import logging\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests\n",
    "import psutil\n",
    "from tensorflow.python.profiler import profiler_v2 as profiler\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tqdm import tqdm\n",
    "import colorama\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')  # Updated method\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logging setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize colorama for colored output\n",
    "colorama.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"FIFTYONE_DEFAULT_DATASET_DIR\"] = \"/home/florian/\"\n",
    "fo.config.dataset_zoo_dir = \"/home/florian/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = augment_image(image)\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset, batch_size=8, shuffle_buffer=1000):\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(shuffle_buffer)\n",
    "    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Food101**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food101_train = tfds.load('food101', split='train', as_supervised=True)\n",
    "food101_val = tfds.load('food101', split='validation', as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Open Images V7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_preprocess_image(path, label):\n",
    "    try:\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "        img = tf.image.resize(img, (224, 224))\n",
    "        img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "        return img, label\n",
    "    except tf.errors.InvalidArgumentError as e:\n",
    "        logging.error(f\"Error processing image at path {path}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def fiftyone_to_tf_dataset(fo_dataset):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    total_samples = 0\n",
    "    skipped_samples = 0\n",
    "\n",
    "    for sample in fo_dataset.iter_samples():\n",
    "        total_samples += 1\n",
    "        \n",
    "        # Check for labels in different possible fields\n",
    "        label = None\n",
    "        if hasattr(sample, 'ground_truth'):\n",
    "            label = sample.ground_truth.label\n",
    "        elif hasattr(sample, 'positive_labels') and sample.positive_labels:\n",
    "            if sample.positive_labels.classifications:\n",
    "                label = sample.positive_labels.classifications[0].label\n",
    "        elif hasattr(sample, 'detections') and sample.detections:\n",
    "            if sample.detections.detections:\n",
    "                label = sample.detections.detections[0].label\n",
    "        \n",
    "        if label in food_classes:\n",
    "            image_paths.append(sample.filepath)\n",
    "            labels.append(food_classes.index(label))\n",
    "        else:\n",
    "            skipped_samples += 1\n",
    "            continue\n",
    "\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Skipped samples: {skipped_samples}\")\n",
    "    print(f\"Processed samples: {len(image_paths)}\")\n",
    "\n",
    "    if not image_paths:\n",
    "        raise ValueError(\"No samples matched the criteria. Check your food_classes and dataset labels.\")\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.filter(lambda x, y: x is not None and y is not None)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_classes = [\"Food\", \"Egg (Food)\", \"Fast food\", \"Seafood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_v7_train = foz.load_zoo_dataset(\n",
    "    \"open-images-v7\",\n",
    "    split=\"train\",\n",
    "    classes=food_classes,\n",
    "    max_samples=50000,  # Adjust as needed if we want more Samples\n",
    "    only_matching=True,\n",
    ")\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(f\"Dataset info: {open_v7_train}\")\n",
    "print(f\"Number of samples: {len(open_v7_train)}\")\n",
    "print(f\"Sample fields: {open_v7_train.first().field_names}\")\n",
    "\n",
    "# Convert to TensorFlow dataset\n",
    "open_v7_train_tf = fiftyone_to_tf_dataset(open_v7_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_v7_val = foz.load_zoo_dataset(\n",
    "    \"open-images-v7\",\n",
    "    split=\"validation\",\n",
    "    classes=food_classes,\n",
    "    max_samples=5000,  # Adjust\n",
    "    only_matching=True,\n",
    ")\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(f\"Dataset info: {open_v7_val}\")\n",
    "print(f\"Number of samples: {len(open_v7_val)}\")\n",
    "print(f\"Sample fields: {open_v7_val.first().field_names}\")\n",
    "\n",
    "# Convert to TensorFlow dataset\n",
    "open_v7_val_tf = fiftyone_to_tf_dataset(open_v7_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Class lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from C:\\Users\\Troxi\\tensorflow_datasets\\food101\\2.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes: 105\n"
     ]
    }
   ],
   "source": [
    "# Get Food101 class labels\n",
    "food101_info = tfds.builder('food101').info\n",
    "food101_labels = food101_info.features['label'].names\n",
    "\n",
    "# Combine with Open Images V7 food classes\n",
    "class_labels = food101_labels + food_classes\n",
    "\n",
    "# Make sure class_labels is a list and has unique values\n",
    "class_labels = list(set(class_labels))\n",
    "\n",
    "# Print the number of classes\n",
    "print(f\"Total number of classes: {len(class_labels)}\")\n",
    "\n",
    "# Update num_classes\n",
    "num_classes = len(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (32, 224, 224, 3) (32,)\n",
      "Validation dataset shape: (32, 224, 224, 3) (32,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_food101(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    return image, tf.cast(label, tf.int32)\n",
    "\n",
    "def preprocess_open_images(image, label):\n",
    "    image = tf.ensure_shape(image, (224, 224, 3))\n",
    "    return image, tf.cast(label, tf.int32)\n",
    "\n",
    "# Preprocess Food101 dataset\n",
    "food101_train = food101_train.map(preprocess_food101, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "food101_val = food101_val.map(preprocess_food101, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Preprocess Open Images dataset\n",
    "open_v7_train_tf = open_v7_train_tf.map(preprocess_open_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "open_v7_val_tf = open_v7_val_tf.map(preprocess_open_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Now combine the datasets\n",
    "train_dataset = food101_train.concatenate(open_v7_train_tf)\n",
    "val_dataset = food101_val.concatenate(open_v7_val_tf)\n",
    "\n",
    "# Then continue with your existing code for preparing the datasets\n",
    "train_dataset = prepare_dataset(train_dataset)\n",
    "val_dataset = prepare_dataset(val_dataset)\n",
    "\n",
    "# Print shapes to verify\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(\"Train dataset shape:\", images.shape, labels.shape)\n",
    "\n",
    "for images, labels in val_dataset.take(1):\n",
    "    print(\"Validation dataset shape:\", images.shape, labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_labels)\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "# Use mixed precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_model.keras', \n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    checkpoint,\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=3)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def grad_accumulation_step(model, x, y, optimizer, acc_gradients, num_accumulation_steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y, logits)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    for i in range(len(acc_gradients)):\n",
    "        acc_gradients[i] += gradients[i]\n",
    "    if tf.equal(optimizer.iterations % num_accumulation_steps, 0):\n",
    "        optimizer.apply_gradients(zip(acc_gradients, model.trainable_variables))\n",
    "        for i in range(len(acc_gradients)):\n",
    "            acc_gradients[i].assign(tf.zeros_like(acc_gradients[i]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom logger\n",
    "class ColoredLogger(logging.Logger):\n",
    "    def __init__(self, name, level=logging.NOTSET):\n",
    "        super().__init__(name, level)\n",
    "        self.formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        self.console_handler = logging.StreamHandler()\n",
    "        self.console_handler.setFormatter(self.formatter)\n",
    "        self.addHandler(self.console_handler)\n",
    "\n",
    "    def info(self, msg, *args, **kwargs):\n",
    "        self._log(logging.INFO, f\"\\033[92m{msg}\\033[0m\", args, **kwargs)\n",
    "\n",
    "    def warning(self, msg, *args, **kwargs):\n",
    "        self._log(logging.WARNING, f\"\\033[93m{msg}\\033[0m\", args, **kwargs)\n",
    "\n",
    "    def error(self, msg, *args, **kwargs):\n",
    "        self._log(logging.ERROR, f\"\\033[91m{msg}\\033[0m\", args, **kwargs)\n",
    "\n",
    "# Set up logging\n",
    "logging.setLoggerClass(ColoredLogger)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# ... (rest of the imports and GPU setup)\n",
    "\n",
    "# Memory usage logging\n",
    "def log_memory_usage():\n",
    "    process = psutil.Process()\n",
    "    memory_info = process.memory_info()\n",
    "    memory_usage = memory_info.rss / 1024 / 1024  # in MB\n",
    "    logger.info(f\"Memory usage: {memory_usage:.2f} MB\")\n",
    "\n",
    "# Training with gradient accumulation and improved logging\n",
    "def train_model(model, train_dataset, val_dataset, epochs, steps_per_epoch, num_accumulation_steps):\n",
    "    acc_gradients = [tf.Variable(tf.zeros_like(tv)) for tv in model.trainable_variables]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        logger.info(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Training metrics\n",
    "        train_loss = tf.keras.metrics.Mean()\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        \n",
    "        train_iter = iter(train_dataset.repeat())\n",
    "        \n",
    "        with tqdm(total=steps_per_epoch, desc=f\"Training\", unit=\"step\") as pbar:\n",
    "            for step in range(steps_per_epoch):\n",
    "                x, y = next(train_iter)\n",
    "                loss = grad_accumulation_step(model, x, y, optimizer, acc_gradients, num_accumulation_steps)\n",
    "                train_loss(loss)\n",
    "                train_accuracy(y, model(x, training=True))\n",
    "                \n",
    "                if (step + 1) % num_accumulation_steps == 0:\n",
    "                    pbar.update(num_accumulation_steps)\n",
    "                    pbar.set_postfix({\"Loss\": f\"{train_loss.result():.4f}\", \"Accuracy\": f\"{train_accuracy.result():.4f}\"})\n",
    "                \n",
    "        gc.collect()\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = tf.keras.metrics.Mean()\n",
    "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        \n",
    "        for x, y in val_dataset:\n",
    "            y_pred = model(x, training=False)\n",
    "            val_loss(tf.keras.losses.sparse_categorical_crossentropy(y, y_pred))\n",
    "            val_accuracy(y, y_pred)\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        logger.info(f\"Epoch {epoch+1} results:\")\n",
    "        logger.info(f\"  Train Loss: {train_loss.result():.4f}, Train Accuracy: {train_accuracy.result():.4f}\")\n",
    "        logger.info(f\"  Val Loss: {val_loss.result():.4f}, Val Accuracy: {val_accuracy.result():.4f}\")\n",
    "        log_memory_usage()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "base_model.trainable = True\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 8  # Define batch_size (adjust as needed)\n",
    "total_samples = len(food101_train) + len(open_v7_train) \n",
    "steps_per_epoch = total_samples // batch_size\n",
    "\n",
    "train_model(model, train_dataset, val_dataset, epochs=10, steps_per_epoch=steps_per_epoch, num_accumulation_steps=4)\n",
    "\n",
    "# Save the model\n",
    "model.save('food_recognition_modelV2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_food(image_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nutrition data integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition_data = pd.read_csv(\"Nutrition-Data/nutrients_csvfile.csv\")\n",
    "\n",
    "def get_nutrition_info(food_item):\n",
    "    try:\n",
    "        nutrition = nutrition_data[nutrition_data['food_item'] == food_item].iloc[0]\n",
    "        return {\n",
    "            'calories': nutrition['calories'],\n",
    "            'protein': nutrition['protein'],\n",
    "            'carbs': nutrition['carbs'],\n",
    "            'fat': nutrition['fat']\n",
    "        }\n",
    "    except IndexError:\n",
    "        return get_nutrition_info_from_api(food_item)\n",
    "\n",
    "# API CALL WHEN NUTRITION VALUERS ARE NOT IN THE LOCAL DATASET\n",
    "API_KEY = \"hydUyBjWVdUlt1qNIeB2dKGgQYbjFiQwMjm6YpBn\" \n",
    "API_ENDPOINT = \"https://api.nal.usda.gov/fdc/v1/foods/search\"\n",
    "\n",
    "def get_nutrition_info_from_api(food_item):\n",
    "    params = {\n",
    "        \"api_key\": API_KEY,\n",
    "        \"query\": food_item,\n",
    "        \"dataType\": [\"Survey (FNDDS)\"],\n",
    "        \"pageSize\": 1\n",
    "    }\n",
    "    \n",
    "    response = requests.get(API_ENDPOINT, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data['foods']:\n",
    "            food = data['foods'][0]\n",
    "            nutrients = food['foodNutrients']\n",
    "            \n",
    "            nutrition_info = {\n",
    "                'calories': next((n['value'] for n in nutrients if n['nutrientName'] == 'Energy'), None),\n",
    "                'protein': next((n['value'] for n in nutrients if n['nutrientName'] == 'Protein'), None),\n",
    "                'carbs': next((n['value'] for n in nutrients if n['nutrientName'] == 'Carbohydrate, by difference'), None),\n",
    "                'fat': next((n['value'] for n in nutrients if n['nutrientName'] == 'Total lipid (fat)'), None)\n",
    "            }\n",
    "            \n",
    "            return nutrition_info\n",
    "    \n",
    "    # If API call fails or no data found, return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def food_recognition_and_nutrition(image_path):\n",
    "    try:\n",
    "        predicted_class_index = predict_food(image_path)\n",
    "        food_item = class_labels[predicted_class_index]\n",
    "        nutrition_info = get_nutrition_info(food_item)\n",
    "        \n",
    "        return {\n",
    "            'food_item': food_item,\n",
    "            'nutrition_info': nutrition_info\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in food recognition: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFLITE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFLite conversion\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('food_recognition_model_v2.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"TensorFlow Lite model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
